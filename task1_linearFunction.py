#<Network builder>
from ann import layers
from ann.weightInitializers import Inintializers
from ann.models import Model

#<Network compile>
from ann import lossFunctions
from ann import optimizers

#<Dataset>
from datasets import loader

#<Visualizer>
from plot import historyVisualizer

from tqdm import tqdm

import numpy as np

class TaskOneModel(Model):
    '''
    ann.models.Model í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„
    ë…¼ë¬¸ì˜ Task (2)ì— ì í•©í•œ ë©”ì†Œë“œë¥¼ ì¶”ê°€í•˜ì—¬ ì¬ì •ì˜í•œ Model ìƒì„± í´ë˜ìŠ¤
    '''
    def update_on_epoch(self, x, y):
        '''
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ êµ¬ë¶„ëœ ë°ì´í„°ì…‹ ìŒ x, yë¥¼ ì…ë ¥ë°›ì•„,
        ë„¤íŠ¸ì›Œí¬ epoch 1íšŒ ê°±ì‹  í›„, loss ë¦¬ìŠ¤íŠ¸ ë° Î”h_BP ë˜ëŠ” Î”h_FA ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        '''
        dataset_iter = tqdm(zip(x, y), total=len(x))

        losses, dhs = [], [] #dhs: Î”h list
        for x, y in dataset_iter:
            y_hat = self.predict(x=x)
            loss = self.lossFunction.forwardProp(y_hat=y_hat, y=y)

            dLoss = self.lossFunction.backProp()

            #Î”h_BP = transpose(W)Â·e, Î”h_FA = BÂ·e
            dh = self.output_layer.backProp(dy=dLoss)

            self.update_on_batch(dLoss)
            dataset_iter.set_description(f'Loss: {loss:.5f}')
            dh = np.mean(dh, axis=0)

            losses.append(loss)
            dhs.append(dh)
        return losses, dhs

    def inference(self, x, y):
        '''
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ëœ ë°ì´í„°ì…‹ ìŒ x, yë¥¼ ì…ë ¥ë°›ì•„ ì¶”ë¡ (inference) í›„,
        lossì˜ ë³€í™”ì— ëŒ€í•œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        '''
        dataset_iter = tqdm(zip(x, y), total=len(x))
        
        losses = []
        for x, y in dataset_iter:
            y_hat = self.predict(x=x)
            loss = self.lossFunction.forwardProp(y_hat=y_hat, y=y)

            dataset_iter.set_description(f'Loss: {loss:.5f}')
            losses.append(loss)
        return losses

    def update_network(self, dataset, epoch: int, batch_size: int):
        '''
        ì…ë ¥ë°›ì€ `dataset`ì„ `batch_size` ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ `epoch` ë§Œí¼ ë„¤íŠ¸ì›Œí¬ë¥¼ ê°±ì‹ í•œ í›„,
        í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ Loss ë³€í™” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜ 
        '''
        test_x, test_y = dataset.loadTestDataset(batch_size=1, is_shuffle=False)

        total_train_losses = []
        total_test_losses = []
        total_dh_list = []
        for e in range(epoch):
            print(f'EPOCH ({e+1}/{epoch})')
            train_x, train_y = dataset.loadTrainDataset(batch_size=batch_size, is_shuffle=True)

            train_losses, dhs = self.update_on_epoch(x=train_x, y=train_y)
            test_losses = self.inference(x=test_x, y=test_y)
            print()

            test_loss = sum(test_losses) / len(test_losses)

            total_train_losses.extend(train_losses)
            total_test_losses.append(test_loss)
            total_dh_list.extend(dhs)
        return total_train_losses, total_test_losses, total_dh_list

def create_network(affine_type: str='BP'):
    '''
    `Task (1) Linear function approximation`ì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ ë°˜í™˜

    30-20-10 ì„ í˜• ë„¤íŠ¸ì›Œí¬ê°€ ì„ í˜• í•¨ìˆ˜, ğ‘‡ë¥¼ ê·¼ì‚¬í•˜ë„ë¡ í•™ìŠµí•˜ì˜€ë‹¤.
    ğµëŠ” ê· ì¼ ë¶„í¬ [âˆ’0.5, 0.5]ì—ì„œ ì¶”ì¶œëœë‹¤(=TaskInit).
    (Methods Summary ì°¸ì¡°)
    '''
    if affine_type == 'BP': #Back Propagation
        AffineLayer = layers.BPLayer
    elif affine_type == 'FA': #Feedback Alignment
        AffineLayer = layers.FALayer
    else: #except
        raise  Exception('\n\n\nThe parameter `affine_type` must be "BP" or "FA" in string format.\n\n')

    inputs = layers.InputLayer(shape=(30, ))
    out = AffineLayer(input_shape=30, units=20, weight_init=Inintializers.TaskInit)(inputs)
    out = AffineLayer(input_shape=20, units=10, weight_init=Inintializers.TaskInit)(out)
    model = TaskOneModel(inputs=inputs, outputs=out)
    return model

if __name__ == '__main__':
    EPOCH = 2
    BATCH_SIZE = 8
    LEARNING_RATE = 0.005

    dataset = loader.LinearFunctionApproximation(train_dataset_size=25000, input_shape=30, output_shape=10, is_normalize=True)

    bp_model = create_network(affine_type='BP')
    fa_model = create_network(affine_type='FA')

    bp_model.compile(lossFunction=lossFunctions.SE(), optimizer=optimizers.SGD(learning_rate=LEARNING_RATE))
    fa_model.compile(lossFunction=lossFunctions.SE(), optimizer=optimizers.SGD(learning_rate=LEARNING_RATE))

    bp_train_his, bp_test_his, h_BPs = bp_model.update_network(dataset=dataset, epoch=EPOCH, batch_size=BATCH_SIZE)
    fa_train_his, fa_test_his, h_FAs = fa_model.update_network(dataset=dataset, epoch=EPOCH, batch_size=BATCH_SIZE)

    print(h_BPs)
    exit()
    
    historyVisualizer.visualize(
        path='./plot/images/task1_linearFunction.png',
        train_losses={'BP': bp_train_his, 'FA': fa_train_his},
        test_losses={'BP': bp_test_his, 'FA': fa_test_his},
        epoch=EPOCH, tick_step=100
    )