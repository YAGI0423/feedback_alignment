from abc import abstractmethod, ABCMeta

import pickle
import numpy as np

class LoaderFrame(metaclass=ABCMeta):
    @abstractmethod
    def _readDataset(self):
        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ, ë°ì´í„°ì…‹ ìƒì„± ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸°
        pass

    def _shuffle_dataset(self, x, y):
        dataset_size = x.shape[0]

        shuffle_idx = list(range(dataset_size))
        np.random.shuffle(shuffle_idx)
        return x[shuffle_idx], y[shuffle_idx]

    def _split_dataset(self, x, batch_size):
        dataset_size = x.shape[0]

        split_size = int(dataset_size / batch_size)
        x = np.array_split(x, split_size)
        return x

    def loadTrainDataset(self, batch_size: int=1, is_shuffle: bool=False):
        x, y = self._x_train.copy(), self._y_train.copy()

        if is_shuffle:
            x, y = self._shuffle_dataset(x=x, y=y)

        x = self._split_dataset(x=x, batch_size=batch_size)
        y = self._split_dataset(x=y, batch_size=batch_size)
        return x, y

    def loadTestDataset(self, batch_size: int=1, is_shuffle: bool=False):
        x, y = self._x_test.copy(), self._y_test.copy()

        if is_shuffle:
            x, y = self._shuffle_dataset(x=x, y=y)
        
        x = self._split_dataset(x=x, batch_size=batch_size)
        y = self._split_dataset(x=y, batch_size=batch_size)
        return x, y

class LinearFunctionApproximation(LoaderFrame):
    '''
    Task (1) 'Linear function approximation'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹

    ëª©í‘œ ì„ í˜• í•¨ìˆ˜ ğ‘‡ëŠ” 30ì°¨ì› ê³µê°„ì˜ ë²¡í„°ë¥¼ 10ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì˜€ë‹¤.
    ğ‘‡ì˜ ìš”ì†ŒëŠ” ë¬´ì‘ìœ„ë¡œ, [âˆ’1, 1] ë²”ìœ„ë¡œë¶€í„° ê· ì¼í•˜ê²Œ ì¶”ì¶œë˜ì—ˆë‹¤.
    ë°ì´í„°ì…‹ ğ· = {(ğ‘¥1, ğ‘¦1), â‹¯ (ğ‘¥ğ‘, ğ‘¦ğ‘)}ëŠ” ğ‘¥ğ‘– ~ ğ‘(ğœ‡ = 0, âˆ‘ = ğ¼)ì¸,ğ‘¦ğ‘– = ğ‘‡ğ‘¥ğ‘–ì— ë”°ë¼ ìƒì„±ë˜ì—ˆë‹¤.
    (Full Methods ì°¸ì¡°)
    '''
    def __init__(self, train_dataset_size, input_shape=30, output_shape=10):
        (self._x_train, self._y_train), (self._x_test, self._y_test) = \
            self._readDataset(input_shape, output_shape, train_dataset_size)

    def _readDataset(self, input_shape, output_shape, train_dataset_size):
        total_dataset = int(train_dataset_size * 1.25)
        X = np.random.normal(
            loc=0, #mean
            scale=train_dataset_size, #deviation distribution
            size=(total_dataset, input_shape)
        )
        T = np.random.rand(input_shape, output_shape) * 2 - 1
        Y = np.matmul(X, T)

        x_train, x_test = X[:train_dataset_size], X[train_dataset_size:]
        y_train, y_test = Y[:train_dataset_size], Y[train_dataset_size:]
        return (x_train, y_train), (x_test, y_test)

class Mnist(LoaderFrame):
    '''
    Task (2) 'MNIST dataset'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹

    ë„¤íŠ¸ì›Œí¬ëŠ” 0-9ì˜ í•„ê¸° ìˆ«ì ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ë„ë¡ í•™ìŠµë˜ì—ˆë‹¤.
    í‘œì¤€ ì›-í•« í‘œí˜„ì€ ì›í•˜ëŠ”(desired) ì¶œë ¥ì„ ì½”ë”©í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆë‹¤.

    ë„¤íŠ¸ì›Œí¬ëŠ” ê¸°ë³¸ MNIST ë°ì´í„°ì…‹[17] 60,000ê°œì˜ ì´ë¯¸ì§€ë¡œ í•™ìŠµë˜ì—ˆë‹¤.
    ê·¸ë¦¬ê³  ì„±ëŠ¥ì€ 10,000ê°œì˜ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ì…‹ì—ì„œ ë°œìƒí•œ ì˜¤ì°¨ì˜ ë°±ë¶„ìœ¨ë¡œ ì¸¡ì •ë˜ì—ˆë‹¤.
    (Methods Summary ì°¸ì¡°)

    â€» MNIST datasetì€ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤ â€»
    '''
    def __init__(
        self,
        is_normalize: bool=False,
        is_one_hot: bool=False,
        path: str='./datasets/mnist_dataset.pk'):

        (self._x_train, self._y_train), (self._x_test, self._y_test) = \
            self._readDataset(path=path, is_normalize=is_normalize, is_one_hot=is_one_hot)
    
    def __sparse_to_oneHot(self, y):
        CLASS_NUM = 10
        y = y.reshape(-1)
        return np.eye(CLASS_NUM)[y]

    def __normalize(self, x):
        '''
        ë°ì´í„°ì…‹ì„ -1. ~ +1. ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ ë°˜í™˜
        '''
        return 2. * (x / 255.) - 1

    def _readDataset(self, path: str, is_normalize: bool=False, is_one_hot: bool=False):
        with open(path, 'rb') as fr:
            mnist_dataset = pickle.load(fr)

        x_train, y_train = mnist_dataset['x_train'], mnist_dataset['y_train']
        x_test, y_test = mnist_dataset['x_test'], mnist_dataset['y_test']

        if is_one_hot:
            y_train = self.__sparse_to_oneHot(y_train)
            y_test = self.__sparse_to_oneHot(y_test)

        if is_normalize:
            x_train = self.__normalize(x_train)
            x_test = self.__normalize(x_test)

        return (x_train, y_train), (x_test, y_test)

class NonlinearFunctionApproximation(LoaderFrame):
    '''
    Task (3) 'Noninear function approximation'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹

    ë°ì´í„°ì…‹ ğ· = {(ğ‘¥1, ğ‘¦1), â‹¯ (ğ‘¥ğ‘, ğ‘¦ğ‘)}ëŠ” ğ‘¥ğ‘– ~ ğ‘(ğœ‡ = 0, âˆ‘ = ğ¼)ì¸, ğ‘¦ğ‘– = ğ‘‡(ğ‘¥ğ‘–)ì— ë”°ë¼ ìƒì„±ë˜ì—ˆë‹¤.
    '''
    def __init__(self, train_dataset_size, input_shape=30, output_shape=10):
        (self._x_train, self._y_train), (self._x_test, self._y_test) = \
            self._readDataset(input_shape, output_shape, train_dataset_size)

    def _readDataset(self, input_shape, output_shape, train_dataset_size):
        from datasets import thirdTaskTargetNet
        T = thirdTaskTargetNet.getNetwork(input_shape=input_shape, output_shape=output_shape)

        total_dataset = int(train_dataset_size * 1.25)
        X = np.random.normal(
            loc=0, #mean
            scale=train_dataset_size, #deviation distribution
            size=(total_dataset, input_shape)
        )
        Y = T.predict(x=X)

        x_train, x_test = X[:train_dataset_size], X[train_dataset_size:]
        y_train, y_test = Y[:train_dataset_size], Y[train_dataset_size:]
        return (x_train, y_train), (x_test, y_test)